{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c8a6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-01T08:14:33.728556 - using 'en_core_web_md'\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA # cf. 'reduce_diminsions()' in the below\n",
    "import datetime\n",
    "import numpy as np\n",
    "import spacy\n",
    "import math\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "possible = {\n",
    "    \"small\":\"en_core_web_sm\",\n",
    "    \"mid\":\"en_core_web_md\",\n",
    "    \"large\":\"en_core_web_lg\"\n",
    "}\n",
    "pretrained_language_model = possible[\"mid\"]\n",
    "nlp = spacy.load(pretrained_language_model)\n",
    "INPUT_FILE=\"data.psv\" # 3000 products of something like that\n",
    "# INPUT_FILE=\"test.psv\" # 6 simple things  \n",
    "\n",
    "msg = f\"using '{pretrained_language_model}'\"\n",
    "print(f\"{datetime.datetime.now().isoformat()} - {msg}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "109504d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_letter(num):\n",
    "    x = num\n",
    "    if num <= 0:\n",
    "        raise ValueError(\"Input must be a positive integer.\")\n",
    "    \n",
    "    letters = \"\"\n",
    "    while num > 0:\n",
    "        num -= 1\n",
    "        # Map the remainder to the corresponding letter\n",
    "        letters = chr(num % 26 + ord('A')) + letters  \n",
    "        # Divide by 26 to move to the next digit\n",
    "        num //= 26\n",
    "        \n",
    "    return letters\n",
    "\n",
    "lookup = {}\n",
    "sentences = []\n",
    "seen = {} \n",
    "loop = 0 \n",
    "with open(INPUT_FILE, 'r') as file:\n",
    "    for line in file:\n",
    "        \n",
    "        fields = line.strip().split('|')\n",
    "        if loop > 0 and loop < 10000: # 10000: # 100\n",
    "            if len(fields[3]) > 3: \n",
    "                description = fields[3]\n",
    "                activity = fields[2]\n",
    "                if description in seen:\n",
    "                    seen[description] += 1\n",
    "                else:\n",
    "                    seen[description] = 1\n",
    "                    sentences.append(description)\n",
    "                    letter = number_to_letter(len(sentences))\n",
    "                    obj = {\"id\":letter, \"group\":-1, \"activity\": activity}\n",
    "                    lookup[description] = obj\n",
    "        loop += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52143e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup has 2914\n",
      "1|A|Feel limitless powered by our nulu fabric these butterysoft tights will have you bending and stretching with ease\n",
      "2|B|Dinosaurs are from once upon a time.\n",
      "3|C|feel limitless powered by our nulu fabric these butterysoft tights will have you bending and stretching with ease\n",
      "4|D|this insulated tumbler has a folding straw lid and slipfree texture for easy drinking from first til last sip\n",
      "5|E|a reputation a vibe a way of life designed in la for you we made these shorts with french terry fabric for softness you can take anywhere\n",
      "6|F|stand out during sweaty studio workouts in these highrise tights made with fabric thats engineered to keep you feeling cool yet covered\n",
      "7|G|voted most likely to be worn multiple times a week this allsport bra is a favourite for comfort and versatility\n",
      "8|H|from sun salutations to restful moments in savasana this yoga tank flows with you the flexible ribbed texture with a cool smooth sensation feels great next to your skin\n",
      "9|I|train hard adventure harder the abrasionresistant fabric on these versatile joggers can handle burpees and backpacking\n",
      "len(lookup)=2914\n"
     ]
    }
   ],
   "source": [
    "# loop = 0\n",
    "# for sentence in sentences:\n",
    "#     count = len(sentence)\n",
    "#     loop += 1\n",
    "#     print(f\"{loop} {count}\")\n",
    "# print(\"sentences number {}\".format(len(sentences)))\n",
    "print(\"lookup has {}\".format( len(lookup)))\n",
    "# Just show 10\n",
    "loop = 0 \n",
    "for key in lookup: \n",
    "    \n",
    "    v = lookup[key]\n",
    "    id = v[\"id\"]\n",
    "    loop += 1\n",
    "    if loop < 10: \n",
    "        print(\"{}|{}|{}\".format( loop, id, key))\n",
    "print(\"len(lookup)={}\".format(len(lookup)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2df80cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_distance is 3.0771785549057666\n",
      "--- Writing to cluster_output.txt\n",
      "loop|cluster|count|distance\n",
      "0|23|57|-4.65303111200587\n",
      "1|67|48|36.94902535694451\n",
      "2|40|17|-4.65303111200587\n",
      "3|20|26|-1.786582399219177\n",
      "4|66|11|22.550722159496058\n",
      "5|21|38|20.348681113123096\n",
      "6|73|10|8.34260395847846\n",
      "7|11|31|27.679396475198693\n",
      "8|94|50|1.2772647375130084\n",
      "9|18|33|30.106786932703393\n",
      "10|78|36|-14.181692567665822\n",
      "11|57|26|33.34578349928143\n",
      "12|82|39|27.10835886840055\n",
      "13|30|56|29.944864630370212\n",
      "14|76|78|14.334672588722205\n",
      "15|43|26|24.134280929597484\n",
      "16|8|27|20.868790005360538\n",
      "17|86|18|20.49424187213668\n",
      "18|45|35|50.32740642880733\n",
      "19|6|57|10.138854227453661\n",
      "20|4|72|6.477718399324424\n",
      "21|31|41|29.46064739824552\n",
      "22|7|56|5.837776775083257\n",
      "23|84|25|27.654034093900965\n",
      "24|41|39|14.200301931987294\n",
      "25|19|95|34.575825086325544\n",
      "26|74|30|-21.912093727065535\n",
      "27|99|4|-24.803097623342758\n",
      "28|97|52|10.018912401068695\n",
      "29|27|39|-14.509256507980956\n",
      "30|25|39|8.26451842229229\n",
      "31|5|15|-9.32512584513\n",
      "32|88|26|-16.144260257634357\n",
      "33|12|58|29.28083533731079\n",
      "34|75|44|16.92251030876587\n",
      "35|79|55|16.42171642667452\n",
      "36|59|48|16.844630239344287\n",
      "37|13|87|-31.691259271101202\n",
      "38|51|50|29.711808024389946\n",
      "39|32|21|32.55118647612708\n",
      "40|3|68|-17.88738509751878\n",
      "41|90|24|16.0754297928415\n",
      "42|34|19|17.9030719084137\n",
      "43|87|38|29.72542734373022\n",
      "44|80|37|3.0616265981179582\n",
      "45|1|23|-22.599862498569614\n",
      "46|46|11|35.36513470476759\n",
      "47|0|51|4.415394618635171\n",
      "48|15|15|1.01447871774866\n",
      "49|10|22|-0.537794929647076\n",
      "50|22|21|12.738541324190415\n",
      "51|65|22|18.54714369302215\n",
      "52|35|50|-0.1146153288848884\n",
      "53|2|23|29.827175315214298\n",
      "54|52|9|17.45498957165053\n",
      "55|39|36|23.244232577276026\n",
      "56|29|82|37.88703703693756\n",
      "57|48|75|-3.9713713907118073\n",
      "58|98|10|16.048578448849753\n",
      "59|49|47|15.316622985806614\n",
      "60|83|20|17.001990478826983\n",
      "61|42|35|9.530782953966217\n",
      "62|71|6|29.959460327192218\n",
      "63|77|24|4.665352082665832\n",
      "64|61|1|31.90898730703286\n",
      "65|60|41|28.86260960070563\n",
      "66|89|14|4.799115676809116\n",
      "67|62|40|30.29614989111873\n",
      "68|58|12|25.192056756865394\n",
      "69|81|18|6.397992926791194\n",
      "70|24|21|55.63681082191611\n",
      "71|28|19|34.352293914578794\n",
      "72|69|38|9.64802763283788\n",
      "73|17|28|21.14758719677582\n",
      "74|37|18|-3.879548695355797\n",
      "75|64|13|19.876976285508942\n",
      "76|38|6|16.936354804763155\n",
      "77|44|27|26.082901047828997\n",
      "78|9|36|18.923286525853346\n",
      "79|96|21|57.40200109212753\n",
      "80|70|6|21.939989736628533\n",
      "81|56|4|22.991019344937136\n",
      "82|26|3|16.393592845859708\n",
      "83|36|20|35.06392694458585\n",
      "84|16|9|22.06353237433939\n",
      "85|92|27|26.51870749250959\n",
      "86|68|12|4.599028862514945\n",
      "87|50|16|16.458556930782226\n",
      "88|85|15|39.039930631386056\n",
      "89|63|9|27.378599960906456\n",
      "90|54|3|1.3427478216563749\n",
      "91|91|4|-44.27206165307663\n",
      "92|95|5|26.42594954388042\n",
      "93|53|9|22.493708611083036\n",
      "94|14|9|8.73733195372384\n",
      "95|33|16|33.84824172971829\n",
      "96|72|2|28.149015986092067\n",
      "97|47|3|2.109332330061213\n",
      "98|93|1|16.618889792523877\n",
      "99|55|5|39.96750577825622\n",
      "Wrote 100 to cluster_output.txt\n",
      "--- Writing to cluster_output.txt\n",
      "loop|id|group|activity\n",
      "Wrote 2914 to product_output.txt\n",
      "The end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    vectors = []\n",
    "    for sentence in sentences:\n",
    "        tokens = nlp(sentence)\n",
    "        word_vectors = [token.vector for token in tokens]\n",
    "        mean_vector = np.mean(word_vectors, axis=0)\n",
    "        lookup[sentence][\"distance\"] = mean_vector # step 1\n",
    "        vectors.append(mean_vector)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=100, random_state=0).fit(vectors)\n",
    "    group_member_count = {} \n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        label = kmeans.labels_[i]\n",
    "        obj = lookup[sentence]\n",
    "        if label in group_member_count:\n",
    "            group_member_count[label] += 1\n",
    "        else:\n",
    "            group_member_count[label] = 1\n",
    "        lookup[sentence][\"group\"] = label\n",
    "        # print(\"{} {} {}\".format(obj[\"id\"], label,  sentence)) \n",
    "        \n",
    "    # Group sentence vectors by cluster label\n",
    "    cluster_vectors = defaultdict(list)\n",
    "    for i, sentence_vector in enumerate(vectors):\n",
    "        label = kmeans.labels_[i]\n",
    "        cluster_vectors[label].append(sentence_vector)\n",
    "        \n",
    "    # first_vector = vectors[0]\n",
    "    zero_vector = np.zeros(vectors[0].shape)\n",
    "    distances = [np.linalg.norm(vector - zero_vector) for vector in vectors]\n",
    "\n",
    "    # remove noise\n",
    "    # min_distance = min(distances)\n",
    "    print(\"min_distance is {}\".format(min_distance))\n",
    "    distances = [distance - min_distance for distance in distances]\n",
    "    \n",
    "    # Normalize each distance to a scale of X ( 100 is my thinking right now)\n",
    "    scale = 100\n",
    "    max_distance = max(distances)\n",
    "    distances = [(distance / max_distance) * scale for distance in distances]\n",
    "\n",
    "    # Print vectors of each cluster\n",
    "    loop = 0 \n",
    "    cluster_file = \"cluster_output.txt\"\n",
    "    file = open(cluster_file, \"w\")\n",
    "    print(\"--- Writing to {}\".format(cluster_file))\n",
    "    print(\"loop|cluster|count|distance\")\n",
    "    file.write(\"loop|cluster|count|distance\\n\")\n",
    "    for label, vectors in cluster_vectors.items():\n",
    "        msg = f\"{loop}|{label}|{group_member_count[label]}|{distances[loop]}\"\n",
    "        print(msg)\n",
    "        file.write(msg + \"\\n\")\n",
    "        loop += 1\n",
    "    file.close()        \n",
    "    print(\"Wrote {} to {}\".format(loop, cluster_file))\n",
    "    \n",
    "    # Print lookup information of each product\n",
    "    loop = 0 \n",
    "    product_file = \"product_output.txt\"\n",
    "    file = open(product_file, \"w\")\n",
    "    print(\"--- Writing to {}\".format(cluster_file))\n",
    "    print(\"loop|id|group|activity\")\n",
    "    file.write(\"loop|id|group|activity|description\\n\")\n",
    "    for sentence in lookup:\n",
    "        obj = lookup[sentence]\n",
    "        msg = \"{}|{}|{}|{}|{}\".format(loop, obj[\"id\"], obj[\"group\"], obj[\"activity\"], sentence)\n",
    "        # print(msg)\n",
    "        file.write(msg + \"\\n\")\n",
    "        loop += 1\n",
    "    file.close()        \n",
    "    print(\"Wrote {} to {}\".format(loop, product_file))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "except OverflowError as e:\n",
    "    print(\"An OverflowError occurred! Likely too many clusters\")\n",
    "    print(e)\n",
    "print(\"The end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57a14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20054f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
